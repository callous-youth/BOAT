

<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>boat_jit.utils &mdash; BOAT-Jittor 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/custom.css?v=4ff932f8" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=f6245a2f"></script>
      <script src="_static/doctools.js?v=888ff710"></script>
      <script src="_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="L2 Regularization with Jittor" href="l2_regularization_example.html" />
    <link rel="prev" title="boat_jit.hyper_ol" href="boat_jit.hyper_ol.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            BOAT-Jittor
              <img src="_static/logo.jpg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Installation Guide:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="description.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="install_guide.html">Installation and Usage Guide</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="boat_jit.html">BOAT-Jittor Structure</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="boat_jit.html#module-boat_jit.boat_opt">Core Problem Class</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="boat_jit.html#main-subpackages">Main Subpackages</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="boat_jit.dynamic_ol.html">boat_jit.dynamic_ol</a></li>
<li class="toctree-l3"><a class="reference internal" href="boat_jit.fogm.html">boat_jit.fogm</a></li>
<li class="toctree-l3"><a class="reference internal" href="boat_jit.hyper_ol.html">boat_jit.hyper_ol</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">boat_jit.utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-boat_jit.utils.op_utils">boat_jit.utils.op_utils</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="boat_jit.html#module-boat_jit.operation_registry">Extension with Operation_Registry</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Example:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="l2_regularization_example.html">L2 Regularization with Jittor</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">BOAT-Jittor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="boat_jit.html">BOAT-Jittor Structure</a></li>
      <li class="breadcrumb-item active">boat_jit.utils</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/boat_jit.utils.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="boat-jit-utils">
<h1>boat_jit.utils<a class="headerlink" href="#boat-jit-utils" title="Permalink to this heading"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this heading"></a></h2>
</section>
<section id="module-boat_jit.utils.op_utils">
<span id="boat-jit-utils-op-utils"></span><h2>boat_jit.utils.op_utils<a class="headerlink" href="#module-boat_jit.utils.op_utils" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.DynamicalSystemRules">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">DynamicalSystemRules</span></span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#DynamicalSystemRules"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.DynamicalSystemRules" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A class to store and manage gradient operator rules.</p>
<dl class="py method">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.DynamicalSystemRules.get_gradient_order">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_gradient_order</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#DynamicalSystemRules.get_gradient_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.DynamicalSystemRules.get_gradient_order" title="Permalink to this definition"></a></dt>
<dd><p>Get the current gradient operator order.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The current gradient operator order.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[List[str]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.DynamicalSystemRules.set_gradient_order">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">set_gradient_order</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_order</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#DynamicalSystemRules.set_gradient_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.DynamicalSystemRules.set_gradient_order" title="Permalink to this definition"></a></dt>
<dd><p>Set a new gradient operator order.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>new_order</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) – The new gradient operator order to set.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the new order is invalid.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.HyperGradientRules">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">HyperGradientRules</span></span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#HyperGradientRules"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.HyperGradientRules" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A class to store and manage gradient operator rules.</p>
<dl class="py method">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.HyperGradientRules.get_gradient_order">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_gradient_order</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#HyperGradientRules.get_gradient_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.HyperGradientRules.get_gradient_order" title="Permalink to this definition"></a></dt>
<dd><p>Get the current gradient operator order.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The current gradient operator order.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[List[str]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.HyperGradientRules.set_gradient_order">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">set_gradient_order</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_order</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#HyperGradientRules.set_gradient_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.HyperGradientRules.set_gradient_order" title="Permalink to this definition"></a></dt>
<dd><p>Set a new gradient operator order.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>new_order</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) – The new gradient operator order to set.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the new order is invalid.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.ResultStore">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">ResultStore</span></span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#ResultStore"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.ResultStore" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A simple class to store and manage intermediate results of hyper-gradient computation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.ResultStore.add">
<span class="sig-name descname"><span class="pre">add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">result</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#ResultStore.add"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.ResultStore.add" title="Permalink to this definition"></a></dt>
<dd><p>Add a result to the store.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – The name of the result (e.g., ‘gradient_operator_results_0’).</p></li>
<li><p><strong>result</strong> (<em>Dict</em>) – The result dictionary to store.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.ResultStore.clear">
<span class="sig-name descname"><span class="pre">clear</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#ResultStore.clear"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.ResultStore.clear" title="Permalink to this definition"></a></dt>
<dd><p>Clear all stored results.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.ResultStore.get_results">
<span class="sig-name descname"><span class="pre">get_results</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#ResultStore.get_results"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.ResultStore.get_results" title="Permalink to this definition"></a></dt>
<dd><p>Retrieve all stored results.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.average_grad">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">average_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#average_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.average_grad" title="Permalink to this definition"></a></dt>
<dd><p>Divide the gradients of all model parameters by the batch size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>jittor.Module</em>) – The model whose gradients need to be averaged.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – The batch size to divide gradients by.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.cat_list_to_tensor">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">cat_list_to_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_tx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#cat_list_to_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.cat_list_to_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Concatenate a list of tensors into a single flattened tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>list_tx</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – The list of tensors to concatenate.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A single flattened tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>jittor.Var</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.cg_step">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">cg_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Ax</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#cg_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.cg_step" title="Permalink to this definition"></a></dt>
<dd><p>Perform Conjugate Gradient (CG) optimization to solve Ax = b.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Ax</strong> (<em>Callable</em>) – Function that computes the matrix-vector product Ax for a given x.</p></li>
<li><p><strong>b</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – Right-hand side of the equation Ax = b.</p></li>
<li><p><strong>max_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – Maximum number of iterations for the CG method, by default 100.</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Convergence threshold for the residual norm, by default 1e-5.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Solution vector x that approximately solves Ax = b.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[jittor.Var]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.conjugate_gradient">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">conjugate_gradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upper_loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lower_loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">K</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fp_map</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stochastic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#conjugate_gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.conjugate_gradient" title="Permalink to this definition"></a></dt>
<dd><p>Compute hyperparameter gradients using the Conjugate Gradient method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – List of parameters for the lower-level optimization problem.</p></li>
<li><p><strong>hparams</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – List of hyperparameters for the upper-level optimization problem.</p></li>
<li><p><strong>upper_loss</strong> (<em>jittor.Var</em>) – Loss function for the upper-level problem.</p></li>
<li><p><strong>lower_loss</strong> (<em>jittor.Var</em>) – Loss function for the lower-level problem.</p></li>
<li><p><strong>K</strong> (<em>int</em>) – Maximum number of iterations for the Conjugate Gradient method.</p></li>
<li><p><strong>fp_map</strong> (<em>Callable</em>) – Fixed-point map function that computes updates to lower-level parameters.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – Tolerance for early stopping based on convergence, by default 1e-10.</p></li>
<li><p><strong>stochastic</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, recompute the fixed-point map during each iteration, by default False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Hyperparameter gradients computed using the Conjugate Gradient method.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[jittor.Var]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.copy_parameter_from_list">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">copy_parameter_from_list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#copy_parameter_from_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.copy_parameter_from_list" title="Permalink to this definition"></a></dt>
<dd><p>Copy parameters from a list to the parameters of a Jittor model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>jittor.Module</em>) – Jittor model with parameters to be updated.</p></li>
<li><p><strong>z</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – List of variables to copy from.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Updated model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>jittor.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.custom_grad">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">custom_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#custom_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.custom_grad" title="Permalink to this definition"></a></dt>
<dd><p>Compute the vector-Jacobian product for Jittor, mimicking PyTorch’s autograd.grad.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<em>Sequence</em><em>[</em><em>jittor.Var</em><em>]</em>) – Outputs of the differentiated function.</p></li>
<li><p><strong>inputs</strong> (<em>Sequence</em><em>[</em><em>jittor.Var</em><em>]</em>) – Inputs with respect to which the gradient will be computed.</p></li>
<li><p><strong>grad_outputs</strong> (<em>Sequence</em><em>[</em><em>jittor.Var</em><em>]</em><em>, </em><em>optional</em>) – Gradients with respect to the outputs, by default None.</p></li>
<li><p><strong>retain_graph</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to retain the computation graph after computing the gradients, by default False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Gradients with respect to the inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[jittor.Var]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.get_outer_gradients">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">get_outer_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outer_loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#get_outer_gradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.get_outer_gradients" title="Permalink to this definition"></a></dt>
<dd><p>Compute gradients of the outer-level loss with respect to parameters and hyperparameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outer_loss</strong> (<em>jittor.Var</em>) – The scalar loss from the outer-level optimization problem.</p></li>
<li><p><strong>params</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – The list of parameters for which gradients with respect to the outer loss are computed.</p></li>
<li><p><strong>hparams</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – The list of hyperparameters for which gradients with respect to the outer loss are computed.</p></li>
<li><p><strong>retain_graph</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to retain the computation graph after computing the gradients, by default True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Gradients with respect to parameters and hyperparameters.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[List[jittor.Var], List[jittor.Var]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.grad_unused_zero">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">grad_unused_zero</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#grad_unused_zero"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.grad_unused_zero" title="Permalink to this definition"></a></dt>
<dd><p>Compute gradients for inputs with respect to the output, filling missing gradients with zeros.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output</strong> (<em>jittor.Var</em>) – The output tensor to compute gradients for.</p></li>
<li><p><strong>inputs</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – The input tensors to compute gradients with respect to.</p></li>
<li><p><strong>retain_graph</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to retain the computation graph, by default False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Gradients with respect to the inputs, with zeros for unused gradients.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[jittor.Var]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.l2_reg">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">l2_reg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#l2_reg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.l2_reg" title="Permalink to this definition"></a></dt>
<dd><p>Compute the L2 regularization loss for a list of parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>parameters</strong> (<em>Iterable</em><em>[</em><em>jittor.Var</em><em>]</em>) – Model parameters for which the L2 regularization is computed.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>L2 regularization loss.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>jittor.Var</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.list_tensor_matmul">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">list_tensor_matmul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#list_tensor_matmul"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.list_tensor_matmul" title="Permalink to this definition"></a></dt>
<dd><p>Compute the element-wise multiplication and sum of two lists of tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>list1</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – The first list of tensors.</p></li>
<li><p><strong>list2</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – The second list of tensors.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The resulting scalar from element-wise multiplication and summation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>jittor.Var</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.list_tensor_norm">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">list_tensor_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#list_tensor_norm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.list_tensor_norm" title="Permalink to this definition"></a></dt>
<dd><p>Compute the p-norm of a list of tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>list_tensor</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – The list of tensors to compute the norm for.</p></li>
<li><p><strong>p</strong> (<em>float</em><em>, </em><em>optional</em>) – The order of the norm, by default 2 (Euclidean norm).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The computed p-norm of the list of tensors.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>jittor.Var</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the list of tensors is empty.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.manual_update">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">manual_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variables</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#manual_update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.manual_update" title="Permalink to this definition"></a></dt>
<dd><p>Manually update variables using gradients stored in _custom_grad.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<em>jittor.optim.Optimizer</em>) – The Jittor optimizer instance.</p></li>
<li><p><strong>variables</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – A list of Jittor variables to be updated.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>AttributeError</strong> – If a variable does not have the ‘_custom_grad’ attribute.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.neumann">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">neumann</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upper_loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lower_loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fp_map</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#neumann"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.neumann" title="Permalink to this definition"></a></dt>
<dd><p>Compute hyperparameter gradients using the Neumann series approximation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – List of parameters for the lower-level optimization problem.</p></li>
<li><p><strong>hparams</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – List of hyperparameters for the upper-level optimization problem.</p></li>
<li><p><strong>upper_loss</strong> (<em>jittor.Var</em>) – Loss function for the upper-level problem.</p></li>
<li><p><strong>lower_loss</strong> (<em>jittor.Var</em>) – Loss function for the lower-level problem.</p></li>
<li><p><strong>k</strong> (<em>int</em>) – Number of iterations for the Neumann series approximation.</p></li>
<li><p><strong>fp_map</strong> (<em>Callable</em>) – Fixed-point map function that computes updates to lower-level parameters.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – Tolerance for early stopping based on convergence, by default 1e-10.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Hyperparameter gradients computed using the Neumann series approximation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[jittor.Var]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.require_model_grad">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">require_model_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#require_model_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.require_model_grad" title="Permalink to this definition"></a></dt>
<dd><p>Ensure all model parameters require gradients.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<em>jittor.Module</em>) – The model to check and update parameters.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>AssertionError</strong> – If the model is not defined.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.stop_grads">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">stop_grads</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grads</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#stop_grads"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.stop_grads" title="Permalink to this definition"></a></dt>
<dd><p>Detach and stop gradient computation for a list of gradients.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>grads</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – The gradients to process.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Detached gradients with requires_grad set to False.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[jittor.Var]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.stop_model_grad">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">stop_model_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#stop_model_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.stop_model_grad" title="Permalink to this definition"></a></dt>
<dd><p>Stop gradient computation for all parameters in a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<em>jittor.Module</em>) – The model to stop gradients for.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>AssertionError</strong> – If the model is not defined.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.update_grads">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">update_grads</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#update_grads"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.update_grads" title="Permalink to this definition"></a></dt>
<dd><p>Update the custom_grad attribute of the model’s parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>grads</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – Gradients to be applied to the parameters.</p></li>
<li><p><strong>model</strong> (<em>jittor.Module</em>) – Model whose parameters will be updated.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="boat_jit.utils.op_utils.update_tensor_grads">
<span class="sig-prename descclassname"><span class="pre">boat_jit.utils.op_utils.</span></span><span class="sig-name descname"><span class="pre">update_tensor_grads</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grads</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/boat_jit/utils/op_utils.html#update_tensor_grads"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#boat_jit.utils.op_utils.update_tensor_grads" title="Permalink to this definition"></a></dt>
<dd><p>Update gradients for Jittor variables manually.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hparams</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – List of Jittor variables representing the hyperparameters.</p></li>
<li><p><strong>grads</strong> (<em>List</em><em>[</em><em>jittor.Var</em><em>]</em>) – List of gradients corresponding to the hyperparameters.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If a variable is stop_grad and cannot be updated.</p>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="boat_jit.hyper_ol.html" class="btn btn-neutral float-left" title="boat_jit.hyper_ol" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="l2_regularization_example.html" class="btn btn-neutral float-right" title="L2 Regularization with Jittor" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Yaohua Liu.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>